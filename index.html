<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Alexander Gao</title>

    <meta name="author" content="Alexander Gao">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/orange.png">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Alexander Gao</name>
                        </p>
                        <p></p>

                        <p style="text-align:center">
                            <a href="data/AlexanderGao_CV_2022.pdf">CV</a> &nbsp|&nbsp
                            <a href="https://scholar.google.com/citations?user=uoNPrRUAAAAJ">Google Scholar</a>
                                                                           &nbsp|&nbsp
                            <a href="https://github.com/gaoalexander/">Github</a>
                        </p>
                        <p></p>

                        <p>Hello, I'm currently a third-year PhD student in Computer Science at University
                           of Maryland, College Park, advised by <a href="https://www.cs.umd.edu/~lin/">Ming C. Lin</a>.
                        </p>

                        <p> My research goal is to develop novel algorithms for simulation and
                            rendering, by bridging classical geometric techniques and physically based modeling with
                            learning-based paradigms and neural representations. Applications include spatial
                            computing, AR/VR, and robotics.
                        </p>
                        <p>
                            I am interning on the Roblox Core AI team this summer. Previously, I interned at
                            Google GeoAR, and worked as an Applied Scientist at AWS. I received an MS
                            in Computer Science from NYU and a BA in Film Production
                            from USC School of Cinematic Arts.</p>
                        <p>
                            Don't hesitate to reach out at <FONT COLOR=blue>gaoalexander [at] gmail dot com</FONT>.
                        </p>
                        <BR>

                        <p>
                            <b><font size="+1">News:</font></b>
                            <BR>
                            <b><br>Jul 2023:</b>&nbsp;&nbsp;&nbsp;<b><i>Dynamic Mesh-Aware Radiance
                                                                                   Fields</i></b> is accepted to ICCV
                                                2023.
                            <i>Camera-ready version forthcoming.</i>
                            <BR>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/surf-circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                                                src="images/surf-circle.jpg"
                                                                class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:left">
                        <heading>Publications</heading>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                <tr onmouseout="c5_stop()" onmouseover="c5_start()">
                    <td style="padding:20px;width:33.3%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='SNAC_thumbnail'>
                                <img src='images/SNAC_thumbnail.png' width="265"></div>
                            <img src='images/SNAC_thumbnail.png' width="265">
                        </div>
                        <script type="text/javascript">
                function c5_start() {
                  document.getElementById('SNAC_thumbnail').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('SNAC_thumbnail').style.opacity = "0";
                }
                c5_stop()




                        </script>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:top">
                        <a href="https://ai4ce.github.io/SNAC_ICLR/" target="_blank">
                            <papertitle>Learning Simultaneous Navigation and Construction in Grid Worlds</papertitle>
                        </a>
                        <br>
                        International Conference on Learning Representations (ICLR), 2023
                        <br>
                        <br>
                        Wenyu Han, Haoran Wu, Eisuke Hirota, <b>Alexander Gao</b>, Lerrel Pinto, Ludovic Righetti, and
                        Chen Feng.
                        <br>
                        <br>
                        <a href="https://openreview.net/forum?id=NEtep2C7yD" target="_blank">Paper</a> /
                        <a href="https://github.com/ai4ce/SNAC_ICLR" target="_blank">Code</a> /
                        <a href="https://ai4ce.github.io/SNAC_ICLR/" target="_blank">Website</a>
                        <p></p>
                        <p>We propose to study a new learning task, mobile construction, to enable an agent to build
                           designed structures in 1/2/3D grid worlds while navigating in the same evolving environments.
                           Unlike existing robot learning tasks such as visual navigation and object manipulation, this
                           task is challenging because of the interdependence between accurate localization and
                           strategic construction planning. In pursuit of generic and adaptive solutions to this
                           partially observable Markov decision process (POMDP) based on deep reinforcement learning
                           (RL), we design
                           a Deep Recurrent Q-Network (DRQN) with explicit recurrent position estimation in this dynamic
                           grid world. Our extensive experiments show that pre-training this position estimation module
                           before Q-learning can significantly improve the construction performance measured by the
                           intersection-over-union score, achieving the best results in our benchmark of various
                           baselines including model-free and model-based RL, a handcrafted SLAM-based policy, and human
                           players.
                        </p>
                    </td>
                </tr>

                <tr onmouseout="c5_stop()" onmouseover="c5_start()">
                    <td style="padding:20px;width:33.3%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='neuphysics_thumbnail'>
                                <img src='images/neuphysics_thumbnail.png' width="265"></div>
                            <img src='images/neuphysics_thumbnail.png' width="265">
                        </div>
                        <script type="text/javascript">
                function c5_start() {
                  document.getElementById('SNAC_thumbnail').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('SNAC_thumbnail').style.opacity = "0";
                }
                c5_stop()




                        </script>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:top">
                        <a href="https://sites.google.com/view/neuphysics" target="_blank">
                            <papertitle>NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos
                            </papertitle>
                        </a>
                        <br>
                        Conference on Neural Information Processing Systems (NeurIPS), 2022
                        <br>
                        <br>
                        <b>Alexander Gao</b>*, Yi-Ling Qiao*, and Ming C. Lin.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                        <br>
                        <br>
                        <a href="https://arxiv.org/abs/2210.12352" target="_blank">Paper</a> /
                        <a href="https://github.com/gaoalexander/neuphysics" target="_blank">Code</a> /
                        <a href="https://sites.google.com/view/neuphysics" target="_blank">Website</a>
                        <p></p>
                        <p>We present a method for learning 3D geometry and physics parameters of a dynamic scene from
                           only a monocular RGB video input. To decouple the learning of underlying scene geometry from
                           dynamic motion, we represent the scene as a time-invariant signed distance function (SDF)
                           which serves as a reference frame, along with a time-conditioned deformation field. We
                           further bridge this neural geometry representation with a differentiable physics simulator by
                           designing a two-way conversion between the neural field and its corresponding hexahedral
                           mesh, enabling us to estimate physics parameters from the source video by minimizing a cycle
                           consistency loss. Our method also allows a user to interactively edit 3D objects from the
                           source video by modifying the recovered hexahedral mesh, and propagating the operation back
                           to the neural field representation. Experiments show that our method achieves superior mesh
                           and video reconstruction of dynamic scenes compared to other competitive Neural Field
                           approaches, and we provide extensive examples which demonstrate its ability to extract useful
                           3D representations from videos captured with consumer-grade cameras. </p>
                    </td>
                </tr>

                </tbody>
            </table>
            <br>
            <br>
            <em>*Denotes equal contribution.</em>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            This site is based on <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's
                                                                                                           template</a>.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>

</html>

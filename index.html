<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Alexander Gao</title>

    <meta name="author" content="Alexander Gao">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/orange.png">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Alexander Gao</name>
                        </p>
                        <p>I'm a second-year PhD student in Computer Science at University of Maryland, College Park,
                           advised by <a href="https://www.cs.umd.edu/~lin/">Ming C. Lin</a> in the <a
                                    href="gamma.umd.edu">GAMMA Lab</a>.
                        </p>
                        <p>My research draws from a variety of computer science subfields, including computer graphics,
                           machine learning & optimization, scientific computing, and computational geometry, and has
                           applications in fields such as AR/VR and Robotics. Specifically, I aim to develop novel
                           algorithms for simulation and rendering, by bridging classical geometric techniques and
                           physically-based modeling with learning-based paradigms and neural representations.
                        </p>
                        <p>
                            Previously, I worked as an Applied Scientist at AWS Robotics and completed an internship on
                            the GeoAR team at Google. I received a B.A. in Film Production from USC School of Cinematic Arts and
                            an M.S. in Computer Science from NYU's Tandon School of Engineering, where
                            I had the opportunity to work with Ken Perlin and Lerrel Pinto. </p>
                        <p>
                            Please feel welcome to reach out to chat about research or collaboration!
                        </p>
                        <p style="text-align:center">
                            <a href="mailto:gaoalexander@gmail.com">Email</a> &nbsp/&nbsp
                            <a href="data/AlexanderGao_CV_2022.pdf">CV</a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?user=uoNPrRUAAAAJ">Google Scholar</a>
                                                                              &nbsp/&nbsp
                            <a href="https://twitter.com/deedzgao">Twitter</a> &nbsp/&nbsp
                            <a href="https://github.com/gaoalexander/">Github</a>
                        </p>
                        <p>
                            <b><font size="+1">News:</font></b>
                            <BR>
                            <b><br>Jan 2023:</b>&nbsp;&nbsp;&nbsp;<b>Simultaneous Navigation and Construction</b> is
                                                accepted to ICLR 2023. Congratulations to lead author Wenyu Han and all
                                                collaborators!
                            <BR>
                            <b><br>Sept 2022:</b>&nbsp;&nbsp;&nbsp;Our paper <b>NeuPhysics</b> is accepted to NeurIPS
                                                2022!
                            <BR>
                            <b><br>Aug 2022:</b>&nbsp;&nbsp;&nbsp;I began my internship at Google Geo AR.
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/hiking-circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                                                src="images/hiking-circle.jpg"
                                                                class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:left">
                        <heading>Research</heading>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                <tr onmouseout="c5_stop()" onmouseover="c5_start()">
                    <td style="padding:20px;width:33.3%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='SNAC_thumbnail'>
                                <img src='images/SNAC_thumbnail.png' width="265"></div>
                            <img src='images/SNAC_thumbnail.png' width="265">
                        </div>
                        <script type="text/javascript">
                function c5_start() {
                  document.getElementById('SNAC_thumbnail').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('SNAC_thumbnail').style.opacity = "0";
                }
                c5_stop()

                        </script>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:top">
                        <a href="https://ai4ce.github.io/SNAC_ICLR/" target="_blank">
                            <papertitle>Learning Simultaneous Navigation and Construction in Grid Worlds</papertitle>
                        </a>
                        <br>
                        International Conference on Learning Representations (ICLR), 2023
                        <br>
                        <br>
                        Wenyu Han, Haoran Wu, Eisuke Hirota, <b>Alexander Gao</b>, Lerrel Pinto, Ludovic Righetti, and
                        Chen Feng.
                        <br>
                        <br>
                        <a href="https://openreview.net/forum?id=NEtep2C7yD" target="_blank">Paper</a> /
                        <a href="https://github.com/ai4ce/SNAC_ICLR" target="_blank">Code</a> /
                        <a href="https://ai4ce.github.io/SNAC_ICLR/" target="_blank">Website</a>
                        <p></p>
                        <p>We propose to study a new learning task, mobile construction, to enable an agent to build
                           designed structures in 1/2/3D grid worlds while navigating in the same evolving environments.
                           Unlike existing robot learning tasks such as visual navigation and object manipulation, this
                           task is challenging because of the interdependence between accurate localization and
                           strategic construction planning. In pursuit of generic and adaptive solutions to this
                           partially observable Markov decision process (POMDP) based on deep reinforcement learning
                           (RL), we design
                           a Deep Recurrent Q-Network (DRQN) with explicit recurrent position estimation in this dynamic
                           grid world. Our extensive experiments show that pre-training this position estimation module
                           before Q-learning can significantly improve the construction performance measured by the
                           intersection-over-union score, achieving the best results in our benchmark of various
                           baselines including model-free and model-based RL, a handcrafted SLAM-based policy, and human
                           players.
                        </p>
                    </td>
                </tr>

                <tr onmouseout="c5_stop()" onmouseover="c5_start()">
                    <td style="padding:20px;width:33.3%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='neuphysics_thumbnail'>
                                <img src='images/neuphysics_thumbnail.png' width="265"></div>
                            <img src='images/neuphysics_thumbnail.png' width="265">
                        </div>
                        <script type="text/javascript">
                function c5_start() {
                  document.getElementById('SNAC_thumbnail').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('SNAC_thumbnail').style.opacity = "0";
                }
                c5_stop()

                        </script>
                    </td>
                    <td style="padding:20px;width:65%;vertical-align:top">
                        <a href="https://sites.google.com/view/neuphysics" target="_blank">
                            <papertitle>NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos
                            </papertitle>
                        </a>
                        <br>
                        Conference on Neural Information Processing Systems (NeurIPS), 2022
                        <br>
                        <br>
                        <b>Alexander Gao</b>*, Yi-Ling Qiao*, and Ming C. Lin.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                        <br>
                        <br>
                        <a href="https://arxiv.org/abs/2210.12352" target="_blank">Paper</a> /
                        <a href="https://github.com/gaoalexander/neuphysics" target="_blank">Code</a> /
                        <a href="https://sites.google.com/view/neuphysics" target="_blank">Website</a>
                        <p></p>
                        <p>We present a method for learning 3D geometry and physics parameters of a dynamic scene from
                           only a monocular RGB video input. To decouple the learning of underlying scene geometry from
                           dynamic motion, we represent the scene as a time-invariant signed distance function (SDF)
                           which serves as a reference frame, along with a time-conditioned deformation field. We
                           further bridge this neural geometry representation with a differentiable physics simulator by
                           designing a two-way conversion between the neural field and its corresponding hexahedral
                           mesh, enabling us to estimate physics parameters from the source video by minimizing a cycle
                           consistency loss. Our method also allows a user to interactively edit 3D objects from the
                           source video by modifying the recovered hexahedral mesh, and propagating the operation back
                           to the neural field representation. Experiments show that our method achieves superior mesh
                           and video reconstruction of dynamic scenes compared to other competitive Neural Field
                           approaches, and we provide extensive examples which demonstrate its ability to extract useful
                           3D representations from videos captured with consumer-grade cameras. </p>
                    </td>
                </tr>

                </tbody>
            </table>
            <br>
            <br>
            <em>*Denotes equal contribution.</em>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            This site is based on <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's
                                                                                                           template</a>.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>

</html>
